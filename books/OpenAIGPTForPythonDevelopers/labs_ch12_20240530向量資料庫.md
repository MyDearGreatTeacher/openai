## ch 12.將向量資料庫與 OpenAI 結合使用
- 向量資料庫？
- 範例 1：使用 Weaviate 使我們的模型更具上下文感知能力
- 範例 2：在語義搜索中使用 Weaviate 和 OpenAI
- 範例 3：使用 Weaviate 和 OpenAI 進行生成式搜索- 向量資料庫？

## 向量資料庫
- 許多流行的向量資料庫，包括 Faiss、Annoy、Milvus、Weaviate 等。
- 我們將使用 Weaviate。 ==> https://weaviate.io/
- 向量資料庫是一種用於存儲、索引和查詢向量（表示高維空間中數據的數字數位數位數組）的資料庫。
- 向量通常來自將非結構化數據（如圖像、文本或聲音）轉換為可由機器學習模型處理和分析的數位格式，
- 尤其是那些涉及相似性搜索和最近鄰演算法的模型。
- 向量資料庫非常適合某些 AI 應用程式，例如推薦系統、搜尋引擎和自然語言處理，
- 其目標是根據其向量表示找到與查詢項最相似的專案。
- 想像一下，你在一個裝滿書籍的廣闊圖書館里，但不是傳統的體裁或書名，而是每本書都由天空中獨特的星星圖案代表。
- 每個圖案（或“向量”）都代表了一本書的本質——它的主題、風格和內容——被翻譯成一種
- 只有圖書館的神奇望遠鏡（“向量資料庫”）才能理解和解釋的星星語言。
- 將圖書館中的每本書都視為現實世界中的一段數據（文檔、圖像，甚至是聲音剪輯）。
- 將這些書籍轉換為星形模式類似於使用 ML 模型（如 GPT 模型）將非結構化數據轉換為向量。
- 每個向量都是一個數值表示，用於捕獲高維空間中數據的本質。
- 這台望遠鏡很特別 - 可以把它想像成向量資料庫 - 它可以快速掃描夜空（搜索資料庫）並找到與您感興趣的模式相似的模式。
- 當你對一個話題感到好奇時，你向望遠鏡描述它，它會將你的描述轉化為星形圖案。
- 假設你對關於龍的故事很著迷。你把這個傳達給望遠鏡。
- 它創造了一個代表「龍的故事」的星形圖案，並掃描天空，尋找類似的圖案。
- 最接近你的「龍的故事」模式的模式是與你的興趣最相關的書籍（數據）。
- 此過程類似於在向量資料庫中執行相似性搜索，在向量資料庫中，系統查找最接近查詢向量的數據點（向量）。
- 這個比喻的目的是説明你可視化整個概念，從將數據嵌入到向量中到查詢向量資料庫。

- 使用向量資料庫的一些真實範例：
  - 推薦系統：向量資料庫可以將使用者偏好和專案特徵存儲為向量。當使用者搜索產品時，系統會找到最相似的商品進行推薦。
  - 語音辨識：當您與語音助手交談時，您的語音將轉換為向量。助手會搜索最佳匹配項以瞭解您的命令。
  - 圖像搜索：您上傳一張汽車圖片，向量資料庫可説明您查找其他汽車圖片。
    - 該系統將視覺特徵轉換為向量，並將它們與同一資料庫中也表示為向量的其他圖像進行比較。
  - 向量資料庫可以快速有效地查找與查詢向量最相似的向量。
  - 它們使用專門的索引結構來有效地存儲和查詢高維向量。
  - 這些結構，如 k-d 樹、HNSW（分層可導航小世界）圖或基於量化的索引，有助於降低維數並加快對最近鄰的搜索。

## 範例 1：使用 Weaviate向量資料庫使AI模型更具上下文感知能力
- 在此範例中，我們將創建兩個 Docker 容器：一個用於 Weaviate，另一個用於我們的 AI 模型。
- 此範例將使用 Docker Compose 來管理這些容器。
- 敘述:
  - 我們正在構建一個具有單個端點的 API，以與使用者的請求（問題）進行交互。
  - API 會將問題發送給 Weaviate，並從 Weaviate 檢索最相似的上下文。
  - 然後，它會將上下文發送到 OpenAI API 以獲取答案。
  - 答案將被發回給使用者，並且也將存儲在 Weaviate 中以備將來使用。
  - 用戶可以在瀏覽器、終端或任何其他用戶端（如 Postman）中看到 API 的輸出。

- 首先使用以下命令安裝 Docker：
```
# Download the installation script
curl -fsSL https://get.docker.com \
-o get-docker.sh

# Run the installation script
sh get-docker.sh
```
- 您還可以在此處查看作業系統的安裝說明。

- 讓我們創建一個新的虛擬環境：
```
mkvirtualenv vector_db_example
```
然後，讓我們創建資料夾結構：
```
mkdir src/vector_db_example
mkdir src/vector_db_example/app
mkdir src/vector_db_example/weaviate
```
在「app」資料夾中為應用程式建立第一個 Dockerfile：

- src/vector_db_example/app/Dockerfile.app
```
FROM python:3.9-bookworm
WORKDIR /app
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt
COPY . .
EXPOSE 5000
CMD [
    "flask", 
    "--app", 
    "app", 
    "run", 
    "--host=0.0.0.0", 
    "--port=5000", 
    "--debug", 
    "--reload"
]
```
在“weaviate”資料夾中為 Weaviate 创建 Dockerfile：

- src/vector_db_example/weaviate/Dockerfile.weaviate
```
FROM semitechnologies/weaviate:1.23.7
EXPOSE 8080
EXPOSE 50051
CMD [
    "--host", 
    "0.0.0.0", 
    "--port", 
    "8080", 
    "--scheme", 
    "http"
]
```
- Docker Compose 檔 ==> src/vector_db_example/docker-compose.yml
```
version: '3.9'

services:

  app:
    build:
      context: app
      dockerfile: Dockerfile.app
    env_file:
      - app/.env
    ports:
      - "5000:5000"
    volumes:
      - ./app:/app/

  weaviate:
    build:
      context: weaviate
      dockerfile: Dockerfile.weaviate
    ports:
    - 8080:8080
    - 50051:50051
    env_file:
      - weaviate/.env
```
我們還需要為這兩個容器提供一些環境變數。

首先匯出您的 OpenAI API 金鑰：
```
export OPENAI_API_KEY=your-api-key
```
在「app」資料夾中創建一個「.env」檔：

- src/vector_db_example/app/.env
```
OPENAI_API_KEY=$OPENAI_API_KEY
```
在「weaviate」資料夾中創建一個「.env」檔：

- src/vector_db_example/weaviate/.env
```
OPENAI_APIKEY=$OPENAI_API_KEY
# Sets the default number of objects to be returned in a query.
QUERY_DEFAULTS_LIMIT=25
# Allow users to interact with weaviate without auth
AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
# Where should Weaviate Standalone store its data?
PERSISTENCE_DATA_PATH=/var/lib/weaviate
# Default vectorizer module to use
DEFAULT_VECTORIZER_MODULE=text2vec-openai
# Which modules to enable in the setup?
ENABLE_MODULES=text2vec-openai
# Hostname of the weaviate instance
CLUSTER_HOSTNAME=node1

```
在上面的配置中，我們在 Weaviate 中啟用了該模組。此模組允許 Weaviate 使用 OpenAI API（或 Azure OpenAI）獲取向量。text2vec-openai

下面是應用程式的「requirements.txt」檔：

- src/vector_db_example/app/requirements.txt
```
annotated-types==0.6.0
anyio==4.2.0
Authlib==1.3.0
blinker==1.7.0
certifi==2024.2.2
cffi==1.16.0
charset-normalizer==3.3.2
click==8.1.7
cryptography==42.0.2
distro==1.9.0
exceptiongroup==1.2.0
flask==3.0.2
grpcio==1.60.1
grpcio-health-checking==1.60.1
grpcio-tools==1.60.1
h11==0.14.0
httpcore==1.0.2
httpx==0.26.0
idna==3.6
importlib-metadata==7.0.1
itsdangerous==2.1.2
Jinja2==3.1.3
MarkupSafe==2.1.5
openai==1.11.1
protobuf==4.25.2
pycparser==2.21
pydantic==2.6.1
pydantic-core==2.16.2
requests==2.31.0
sniffio==1.3.0
tqdm==4.66.1
typing-extensions==4.9.0
urllib3==2.2.0
validators==0.22.0
weaviate-client==4.4.2
werkzeug==3.0.1
zipp==3.17.0
```
我們在 「requirements.txt」 文件中安裝了 「weaviate-client」、“openai” 和 “flask”。

i️ Flask 是一個用 Python 編寫的微型 Web 框架。它是快速製作 Web 應用程式或 REST API 原型的絕佳選擇。

我們將代碼添加到名為「app.py」的檔中的「app」 資料夾中。

這是項目的檔案樹：
```
src/vector_db_example/
├── app
│   ├── app.py
│   ├── Dockerfile.app
│   ├── .env
│   └── requirements.txt
└── weaviate
    ├── Dockerfile.weaviate
    └── .env

```
讓我們開始構建應用程式的核心部分，即“app.py”檔。

當我們的 API 收到來自使用者的查詢時，它會將其存儲在一個名為的變數中，然後使用查詢和查詢的角色構建字典。question
```
question = request.args.get("q")

user_prompt = {
        "role": "user",
        "content": question        
    }
```
然後，我們使用一個函數從 Weaviate 獲取最近的上下文。此函數將被調用，稍後將在代碼中定義。weaviate_nearest_interactions
```
context = weaviate_nearest_interactions(
    question, 
    weaviate_certainty,
    weaviate_limit,
)
```
在某些情況下，上下文可能是空的或不足以從 OpenAI 獲得好的答案。這就是為什麼我們要在上下文中包括使用者和 AI 之間的最新互動。我們將使用該函數從 Weaviate 獲取最新的互動。此函數將在後面的代碼中定義。weaviate_latest_interactions
```
latest_interactions = weaviate_latest_interactions(
    interactions_limit
)
```
我們還將合併這兩個上下文並刪除任何重複項。
```
global_context = latest_interactions["data"] + context["data"]
# Get unique values
global_context = [
    dict(t) for t in {
        tuple(d.items()) for d in global_context
        }
    ]

```
現在，我們將向OpenAI發送消息以獲得答案。該消息將包含系統提示（例如“您是友好的 AI”）和全域上下文。
```
response = openai_client.chat.completions.create(
    model=model,
    messages=messages,
    max_tokens=200,
    temperature=1.2,
)

content = response.choices[0].message.content.strip()
```
使用者提示和答案將存儲在 Weaviate 中以備將來使用。我們將使用該函數將數據存儲在 Weaviate 中。此函數將在後面的代碼中定義。weaviate_save_data
```
assistant_prompt = {
    "role": "assistant",
    "content": content
}

data = [
    user_prompt,
    assistant_prompt
]

weaviate_save_data(
    data
)

```
最後，我們將回應返回給使用者。出於調試目的，我們還將返回全域上下文。
```
return {
    "response": assistant_prompt["content"],
    "global_context": global_context,
}

```
這是我們將在「app.py」檔中使用的完整函數：
```
@app.route("/ask", methods=["GET"])
def ask():
    # Get the question from the user
    question = request.args.get("q")

    # Build the user prompt
    user_prompt = {
            "role": "user",
            "content": question        
        }

    # Get the nearest context from Weaviate
    context = weaviate_nearest_interactions(
        question, 
        weaviate_certainty,
        weaviate_limit,
    )

    # Get the latest interactions from Weaviate
    latest_interactions = weaviate_latest_interactions(
        interactions_limit
    )

    # Merge the two contexts
    # and get unique values
    global_context = latest_interactions["data"] + context["data"]    
    global_context = [
        dict(t) for t in {
            tuple(d.items()) for d in global_context
            }
        ]

    # Build the message to send to OpenAI
    messages = [system_prompt] + global_context + [user_prompt]
    # Send the message to OpenAI
    response = openai_client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=200,
        temperature=1.2,
    )

    content = response.choices[0].message.content.strip()

    # Save the user prompt and the answer in Weaviate
    assistant_prompt = {
        "role": "assistant",
        "content": content
    }

    data = [
        user_prompt,
        assistant_prompt
    ]

    weaviate_save_data(
        data
    )

    # Return the response to the user
    return {
        "response": assistant_prompt["content"],
        "global_context": global_context,
    }
```
讓我們定義我們在函數中使用的函數。ask
```
def weaviate_nearest_interactions(query, certainty, limit):
    try:
        # Get the nearest context from Weaviate
        result = weaviate_client.query.get(
            class_name=weaviate_class_name,
            properties=[
                "role",
                "content"                                
            ]
        ).with_near_text({
            "concepts": [query],
            "certainty": certainty
        }).with_limit(
            limit
        ).do()
        
        return {
            "data": result['data']['Get'][weaviate_class_name]
        }

    except Exception as e:
        app.logger.error(f"Error while searching: {e}")     

def weaviate_latest_interactions(limit):
    try:
        # Get the latest interactions from Weaviate
        result = weaviate_client.query.get(
            class_name=weaviate_class_name,
            properties=[
                "role",
                "content"                                
            ]
        ).with_limit(
            limit
        ).do()
        
        return {
            "data": result['data']['Get'][weaviate_class_name]
        }

    except Exception as e:
        app.logger.error(f"Error while searching: {e}") 

```
資料庫有一個模式，Weaviate 也不例外。我們需要為資料庫定義架構：
```
schema = {
    "classes": [
        {
            "class": weaviate_class_name,
            "description": "A class to store chat messages",
            "properties": [
                {
                    "name": "content",
                    "description": "The content of the chat message",
                    "dataType": ["text"],
                },
                {
                    "name": "role",
                    "description": "The role of the message",
                    "dataType": ["string"],
                },
            ],
        }
    ]
}

def weaviate_create_schema():
    try:
        # Create the schema in Weaviate
        weaviate_client.schema.create(schema)
        app.logger.info("Schema successfully created.")
    except Exception as e:
        app.logger.error(f"Failed to create schema: {e}")

```
當使用者啟動會話時，我們應該在 Weaviate 中創建架構並刪除任何以前的數據。這就是為什麼我們要定義函數：weaviate_delete_data
```
def weaviate_delete_data():
    try:
        weaviate_client.schema.delete_class(
            class_name=weaviate_class_name
        )
        app.logger.info("Data successfully reset.")
    except Exception as e:
        app.logger.error(f"Error while deleting class: {e}")
        return {"error in weaviate_reset": str(e)}, 500

Copy

Explain
weaviate_class_name將被定義為全域變數：

weaviate_class_name = "ChatMessage"

```
為類創建一個唯一的名稱（如 ）可能是個好主意。ChatMessage-{session_id}

當我們編譯所有代碼時，我們最終會得到以下「app.py」檔（通過複製下面的代碼創建檔）：
```
cat << EOF > src/vector_db_example/app/app.py
import weaviate, os
from flask import Flask, request
from openai import OpenAI

app = Flask(__name__)

openai_api_key = os.getenv("OPENAI_API_KEY")
system_prompt = "You are a helpful assitant"
system_prompt ={
        "role": "system",
        "content": system_prompt
    }
model = "gpt-3.5-turbo"
weaviate_class_name = "ChatMessage"
weaviate_limit = 10
interactions_limit = 10
weaviate_certainty = 0.5

openai_client = OpenAI(
    api_key=openai_api_key
)

weaviate_client = weaviate.Client(
    url="http://weaviate:8080",
    auth_client_secret={
        "X-OpenAI-Api-Key": openai_api_key
    }
)

schema = {
    "classes": [
        {
            "class": weaviate_class_name,
            "description": 
                "A class to store chat messages",
            "properties": [
                {
                    "name": "content",
                    "description": 
                        "The content of the chat message",
                    "dataType": ["text"],
                },
                {
                    "name": "role",
                    "description": 
                        "The role of the message",
                    "dataType": ["string"],
                },
            ],
        }
    ]
}

def weaviate_create_schema():
    try:
        weaviate_client.schema.create(schema)
        app.logger.info("Schema successfully created.")
    except Exception as e:
        app.logger.error(f"Failed to create schema: {e}")

def weaviate_delete_data():
    try:
        weaviate_client.schema.delete_class(
            class_name=weaviate_class_name
        )
        app.logger.info("Data successfully reset.")
    except Exception as e:
        app.logger.error(f"Error while deleting class: {e}")
        return {"error in weaviate_reset": str(e)}, 500


weaviate_delete_data()
weaviate_create_schema()

def weaviate_nearest_interactions(query, certainty, limit):
    try:
        result = weaviate_client.query.get(
            class_name=weaviate_class_name,
            properties=[
                "role",
                "content"                                
            ]
        ).with_near_text({
            "concepts": [query],
            "certainty": certainty
        }).with_limit(
            limit
        ).do()
        
        return {
            "data": result['data']['Get'][weaviate_class_name]
        }

    except Exception as e:
        app.logger.error(f"Error while searching: {e}")     

def weaviate_latest_interactions(limit):
    try:
        result = weaviate_client.query.get(
            class_name=weaviate_class_name,
            properties=[
                "role",
                "content"                                
            ]
        ).with_limit(
            limit
        ).do()
        
        return {
            "data": result['data']['Get'][weaviate_class_name]
        }

    except Exception as e:
        app.logger.error(f"Error while searching: {e}")                   

def weaviate_save_data(data):    
    weaviate_client.batch.configure(
        batch_size=100
    )
    with weaviate_client.batch as batch:        
        for _, d in enumerate(data):
            properties = {
                "role": d["role"],
                "content": d["content"]                
            }
            batch.add_data_object(
                properties, 
                weaviate_class_name,
            )

@app.route("/ask", methods=["GET"])
def ask():
    question = request.args.get("q")

    user_prompt = {
            "role": "user",
            "content": question        
        }

    context = weaviate_nearest_interactions(
        question, 
        weaviate_certainty,
        weaviate_limit,
    )

    latest_interactions = weaviate_latest_interactions(
        interactions_limit
    )

    global_context = latest_interactions["data"] + context["data"]
    # Get unique values
    global_context = [
        dict(t) for t in {
            tuple(d.items()) for d in global_context
            }
        ]

    messages = [system_prompt] + global_context + [user_prompt]
    
    response = openai_client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=200,
        temperature=1.2,
    )

    content = response.choices[0].message.content.strip()

    assistant_prompt = {
        "role": "assistant",
        "content": content
    }

    data = [
        user_prompt,
        assistant_prompt
    ]

    weaviate_save_data(
        data
    )

    return {
        "response": assistant_prompt["content"],
        "global_context": global_context,
    }
EOF
```
如果要檢查資料庫的內容以進行調試，還可以在「app.py」檔中添加以下函數：
```
@app.route("/data", methods=["GET"])
def weaviate_get_all_data():
    try:
        result = weaviate_client.query.get(
            class_name=weaviate_class_name,
            properties=[
                "role",
                "content"                                
            ]
        ).do()

        return {
            "data": result['data']['Get'][weaviate_class_name]
        }

    except Exception as e:
        app.logger.error(f"Error while getting data: {e}")
        return {"error in weaviate_data": str(e)}, 500 
```
現在，我們需要構建 Docker 容器並啟動應用程式。我們可以通過執行以下命令來執行此操作：
```
cd src/vector_db_example
docker-compose up --build
```
您可以在瀏覽器中存取 API。http://localhost:5000/ask?q=<your-question>

這是一個很好的例子：
```
# I have a cat
curl http://127.0.0.1:5000/ask?q=I%20have%20a%20cat
# I have a dog
curl http://127.0.0.1:5000/ask?q=I%20have%20a%20dog
# How many pets do I have?
curl http://127.0.0.1:5000/ask?q=How%20many%20pets%20do%20I%20have%3F
```

這是最後一個命令的輸出如下所示：
```
{
  "global_context": [
    {
      "content": "I have a dog",
      "role": "user"
    },
    {
      "content": 
        "That's wonderful! Cats make great companions. "
        "Is there anything specific you need help with "
        "regarding your cat?",
      "role": "assistant"
    },
    {
      "content": 
        "That's great! Dogs are wonderful pets too. "
        "Is there anything specific you need help "
        "with regarding your dog?",
      "role": "assistant"
    },
    {
      "content": "I have a cat",
      "role": "user"
    }
  ],
  "response": 
    "Based on your previous message, you mentioned "
    "having a dog. If you have a cat in addition to "
    "a dog, then you would have two pets."
}
```

## 範例 2：在語義搜索中使用 Weaviate 和 OpenAI
- 敘述
  - 在這個範例中，我們將使用 Weaviate 和 OpenAI 來構建一個語義搜尋引擎。
  - Weaviate 將存儲數據以及表示數據的向量。
  - OpenAI 將用於通過向量執行語義搜索。
- 資料集:
  - 將使用一個CSV數據集，其中包含來自簡單英語維琪百科的文章。
  - 該數據集由 OpenAI 託管。或者，您可以在 Companion Toolkit 中找到相同的數據集。
  - CSV 檔案包含以下欄位：
    - “id”：數據條目的唯一標識符。
    - “url”：維琪百科頁面的URL。
    - “title”：文章的標題。
    - “text”：文章的內容。
    - “content_vector”：內容的向量表示。
  - 請注意，向量化是使用 OpenAI text-embedding-ada-002 模型完成的。

首先建立新的虛擬環境：

```
mkvirtualenv vector_db_semantic_search

```
讓我們為此範例建立新資料夾：

```
mkdir src/vector_db_semantic_search
mkdir -p src/vector_db_semantic_search/app/data
mkdir src/vector_db_semantic_search/weaviate

```
- 下載數據集，解壓，並將檔保存在“src/vector_db_semantic_search/app/data/data.csv”下。
- 或者，我建議下載數據集的子集，因為完整的數據集非常大。
- 下載、提取和輸入Weaviate需要一些時間。
- 您可以在 Companion Toolkit 中找到同一數據集的子集。
- 下載檔並將其保存在「src/vector_db_semantic_search/app/data/data.csv」下。
- 上一個應用程式中的所有內容（Dockerfiles 和 .env 檔，以及“docker-compose.yml”檔和“requirements.txt”）將保持不變。
- 唯一會改變的是“app.py”檔
  - 在我們的應用程式中，我們需要創建架構：
```
article_class = {
    "class": weaviate_class_name,
    "description": 
        "An article from the Simple English Wikipedia data set",
    "vectorizer": "text2vec-openai",
    "moduleConfig": {
        # Match how OpenAI created the embeddings 
        # for the `content` (`text`) field
        "text2vec-openai": {
            "model": "ada",
            "modelVersion": "002",
            "type": "text",
            "vectorizeClassName": False
        }
    },
    "properties": [
        {
            "name": "title",
            "description": "The title of the article",
            "dataType": ["text"],
            # Don't vectorize the title
            "moduleConfig": {"text2vec-openai": {"skip": True}}
        },
        {
            "name": "content",
            "description": "The content of the article",
            "dataType": ["text"],
        }
    ]
}
```
然後使用以下函數將資料匯入 Weaviate：
```
def weaviate_import_data():
    # Counter to show progress on the console
    counter = 0
    interval = 100
    
    csv_iterator = pd.read_csv(
        'data/data.csv',
        usecols=[
            'id', 
            'url', 
            'title', 
            'text', 
            'content_vector'
        ],
        # number of rows per chunk
        chunksize=100,  
        # limit the number of rows to import
        nrows=100
    )   
    
    # Configure batch
    weaviate_client.batch.configure(
        batch_size=100
    )

    with weaviate_client.batch as batch:
        for chunk in csv_iterator:
            for _, row in chunk.iterrows():

                properties = {
                    "title": row.title,
                    "content": row.text,
                    "url": row.url
                }

                # Convert the vector from CSV 
                # string back to array of floats
                vector = ast.literal_eval(
                    row.content_vector
                )

                # Add the object to the batch, 
                # and set its vector embedding
                batch.add_data_object(
                    properties, 
                    class_name=weaviate_class_name,
                    vector=vector
                )

                # Calculate and display progress
                counter += 1
                if counter % interval == 0:
                    app.logger.debug(f"Imported {counter} articles...")
    app.logger.debug(f"Finished importing {counter} articles.")
```
這是我們 API 的主要路由：
```
@app.route("/ask", methods=["GET"])
def ask():
    question = request.args.get("q")

    context = weaviate_semantic_search(
        question, 
    )

    return {
        "response": context
    }
```
當使用者向 API 發送查詢時，API 會將查詢轉發給 Weaviate 以檢索最相似的文章。然後，它將回應返回給使用者。這是使用該函數完成的。weaviate_semantic_search
```
def weaviate_semantic_search(query):
    nearText = {
        "concepts": [query],
    }

    properties = [
        "title", 
        "content",
        "_additional {distance}"
    ]

    limit = 2

    response = weaviate_client.query.get(
        class_name=weaviate_class_name,
        properties=properties,
    ).with_near_text(
        nearText
    ).with_limit(
        limit
    ).do()

    result  = response['data']['Get'][weaviate_class_name]
    return result
```
```
該函數旨在使用指定的查詢在 Weaviate 資料庫中執行語義搜索。weaviate_semantic_search()

該函數的核心是利用 Weaviate 的向量搜索功能來查找與輸入查詢語義相關的條目。
通過構造一個字典，將查詢封裝在鍵下的清單中，它指示 Weaviate 評估資料庫條目與所提供查詢概念的語義接近度。nearTextconcepts

該函數請求匹配條目的 和屬性，以及標記為 的附加資訊。
這一點至關重要，因為它量化了每個返回的條目與向量空間中查詢的接近程度，距離越小表示相似度越高。
titlecontentdistancedistance

使用設置為 2 會限制搜索僅返回前兩個最相關的條目。limit

選擇包含在屬性清單中特別有趣，因為它通過顯示搜索期間計算的原始距離來深入瞭解語義搜索過程。
這提供了一個透明的視圖，說明為什麼某些條目被認為比其他條目更相關。_additional {distance}
```
- 建立「app.py」檔：==> src/vector_db_semantic_search/app/app.py
```python
import weaviate, os, ast
from flask import Flask, request
from openai import OpenAI
import pandas as pd

app = Flask(__name__)

openai_api_key = os.getenv("OPENAI_API_KEY")
model = "gpt-3.5-turbo"
weaviate_class_name = "Article"

openai_client = OpenAI(
    api_key=openai_api_key
)

weaviate_client = weaviate.Client(
    url="http://weaviate:8080",
    auth_client_secret={
        "X-OpenAI-Api-Key": openai_api_key
    }
)

article_class = {
    "class": weaviate_class_name,
    "description": 
        "An article from the Simple English Wikipedia data set",
    "vectorizer": "text2vec-openai",
    "moduleConfig": {
        # Match how OpenAI created the embeddings 
        # for the `content` (`text`) field
        "text2vec-openai": {
            "model": "ada",
            "modelVersion": "002",
            "type": "text",
            "vectorizeClassName": False
        }
    },
    "properties": [
        {
            "name": "title",
            "description": "The title of the article",
            "dataType": ["text"],
            # Don't vectorize the title
            "moduleConfig": {"text2vec-openai": {"skip": True}}
        },
        {
            "name": "content",
            "description": "The content of the article",
            "dataType": ["text"],
        }
    ]
}

def weaviate_import_data():
    counter = 0
    interval = 100
    
    csv_iterator = pd.read_csv(
        'data/data.csv',
        usecols=[
            'id', 
            'url', 
            'title', 
            'text', 
            'content_vector'
        ],
        # number of rows per chunk
        chunksize=100,  
        # limit the number of rows to import
        nrows=100
    )   
    
    # Configure batch
    weaviate_client.batch.configure(
        batch_size=100
    )

    with weaviate_client.batch as batch:
        for chunk in csv_iterator:
            for _, row in chunk.iterrows():

                properties = {
                    "title": row.title,
                    "content": row.text,
                    "url": row.url
                }

                # Convert the vector from CSV 
                # string back to array of floats
                vector = ast.literal_eval(
                    row.content_vector
                )

                # Add the object to the batch, 
                # and set its vector embedding
                batch.add_data_object(
                    properties, 
                    class_name=weaviate_class_name,
                    vector=vector
                )

                # Calculate and display progress
                counter += 1
                if counter % interval == 0:
                    app.logger.debug(f"Imported {counter} articles...")
    app.logger.debug(f"Finished importing {counter} articles.")

def weaviate_semantic_search(query):
    nearText = {
        "concepts": [query],
    }

    properties = [
        "title", 
        "content",
        "_additional {distance}"
    ]

    limit = 2

    response = weaviate_client.query.get(
        class_name=weaviate_class_name,
        properties=properties,
    ).with_near_text(
        nearText
    ).with_limit(
        limit
    ).do()

    result  = response['data']['Get'][weaviate_class_name]
    return result
    
weaviate_client.schema.delete_all()
weaviate_import_data()

@app.route("/ask", methods=["GET"])
def ask():
    question = request.args.get("q")

    context = weaviate_semantic_search(
        question, 
    )

    return {
        "response": context
    }
```
現在，讓我們構建 Docker 容器並啟動應用程式：
```
cd src/vector_db_semantic_search
docker-compose up --build
```
您可以在瀏覽器中存取 API。以下是一些範例：http://localhost:5000/ask?q=<your-question>
```
# search query: politics
curl http://0.0.0.0:5000/ask?q=politics
# search query: science
curl http://0.0.0.0:5000/ask?q=science
# search query: cats
curl http://0.0.0.0:5000/ask?q=cats

```
上述每個命令都將根據搜索查詢從數據集中返回最相關的文章。例如，當您搜索「貓」時，API 會返回與「寵物」、“動物”、“動物學”等相關主題最相關的文章。



## 範例 3：使用 Weaviate 和 OpenAI 進行生成式搜索
- 生成式搜索是一種基於使用者查詢生成新內容的搜索類型。
- 當我們在搜尋引擎中搜索術語時，我們通常會收到與查詢相關的結果清單。
- 但是，在某些情況下，我們可能希望根據查詢生成新內容。
- 例如，如果我們搜索「如何製作蛋糕」，我們可能希望收到蛋糕食譜，而不是包含「如何製作蛋糕」一詞的網站清單。
- 同樣的原則也適用於我們的例子。例如，當我們搜索單詞「cat」時，我們可以根據查詢「cat」和返回的上下文生成一篇關於貓的新文章。
- Weaviate 會根據查詢返回最相關的文章，併發送消息給 OpenAI 根據上下文生成新文章。
- 我們將維護相同的 Dockerfile 和應用程式 .env 檔案，以及“docker-compose.yml案”檔和“requirements.txt”檔案。
- 在此範例中，有兩件事將發生變化：
  - Weaviate 容器的“.env”檔案。
  - “app.py”檔案。

- 為 Weaviate 容器創建「.env」文件： ==> src/vector_db_generative_search/weaviate/.env
```
OPENAI_APIKEY=$OPENAI_API_KEY
QUERY_DEFAULTS_LIMIT=25
AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
PERSISTENCE_DATA_PATH=/var/lib/weaviate
DEFAULT_VECTORIZER_MODULE=text2vec-openai
ENABLE_MODULES=text2vec-openai,generative-openai
CLUSTER_HOSTNAME=node1
```
- 正如你所觀察到的，我們在變數中添加了“generative-openai”。
- 此操作將在 Weaviate 中啟用生成模組。ENABLE_MODULES
- “app.py”檔與前面的示例沒有太大區別。我們將簡單地添加一個新調用，根據 Weaviate 傳回的上下文和提示生成新鮮內容。

例如，如果我們希望 OpenAI 以莎士比亞的風格重寫返回的文章，我們可以使用以下代碼：
```
prompt = """Rewrite in the style of Shakespeare:
{content}
"""

def weaviate_semantic_search(query, prompt):
    nearText = {
        "concepts": [query],
    }

    properties = [
        "title", 
        "content",
        "_additional {distance}"
    ]

    limit = 1

    response = weaviate_client.query.get(
        class_name=weaviate_class_name,
        properties=properties,
    ).with_generate(
        single_prompt=prompt
    ).with_near_text(
        nearText
    ).with_limit(
        limit
    ).do()

    result  = response['data']['Get'][weaviate_class_name]
    return result
```
提示可以是您想要的任何內容。例如，若要將內容翻譯成威爾士語，可以使用以下提示：
```
prompt = """Translate to Welsh:
{content}
"""
```
如您所見，提示包含內容 （） 的佔位元。您可以將任何其他文本或佔位元添加到提示符中（例如 或 ），只要它們存在於 Weaviation 傳回的上下文中即可。{content}{title}{url}

讓我們查看整個“app.py”檔。建立必要的資料夾與檔案（或從上一個範例中複製/貼上它們）：
```
mkdir -p src/vector_db_generative_search/app
..etc
```
- 建立「app.py」檔：  src/vector_db_generative_search/app/app.py
```
import weaviate, os, ast
from flask import Flask, request
from openai import OpenAI
import pandas as pd

app = Flask(__name__)

openai_api_key = os.getenv("OPENAI_API_KEY")
model = "gpt-3.5-turbo"
weaviate_class_name = "Article"

openai_client = OpenAI(
    api_key=openai_api_key
)

weaviate_client = weaviate.Client(
    url="http://weaviate:8080",
    auth_client_secret={
        "X-OpenAI-Api-Key": openai_api_key
    }
)

article_class = {
    "class": weaviate_class_name,
    "description": 
        "An article from the Simple English Wikipedia data set",
    "vectorizer": "text2vec-openai",
    "moduleConfig": {
        # Match how OpenAI created the embeddings 
        # for the `content` (`text`) field
        "text2vec-openai": {
            "model": "ada",
            "modelVersion": "002",
            "type": "text",
            "vectorizeClassName": False
        }
    },
    "properties": [
        {
            "name": "title",
            "description": "The title of the article",
            "dataType": ["text"],
            # Don't vectorize the title
            "moduleConfig": {"text2vec-openai": {"skip": True}}
        },
        {
            "name": "content",
            "description": "The content of the article",
            "dataType": ["text"],
        }
    ]
}

def weaviate_import_data():
    counter = 0
    interval = 100
    
    csv_iterator = pd.read_csv(
        'data/data.csv',
        usecols=[
            'id', 
            'url', 
            'title', 
            'text', 
            'content_vector'
        ],
        # number of rows per chunk
        chunksize=100,  
        # limit the number of rows to import
        nrows=100
    )   
    
    # Configure batch
    weaviate_client.batch.configure(
        batch_size=100
    )

    with weaviate_client.batch as batch:
        for chunk in csv_iterator:
            for _, row in chunk.iterrows():

                properties = {
                    "title": row.title,
                    "content": row.text,
                    "url": row.url
                }

                # Convert the vector from CSV 
                # string back to array of floats
                vector = ast.literal_eval(
                    row.content_vector
                )

                # Add the object to the batch, 
                # and set its vector embedding
                batch.add_data_object(
                    properties, 
                    class_name=weaviate_class_name,
                    vector=vector
                )

                # Calculate and display progress
                counter += 1
                if counter % interval == 0:
                    app.logger.debug(f"Imported {counter} articles...")
    app.logger.debug(f"Finished importing {counter} articles.")

def weaviate_semantic_search(query, prompt):
    nearText = {
        "concepts": [query],
    }

    properties = [
        "title", 
        "content",
        "_additional {distance}"
    ]

    limit = 1

    response = weaviate_client.query.get(
        class_name=weaviate_class_name,
        properties=properties,
    ).with_generate(
        single_prompt=prompt
    ).with_near_text(
        nearText
    ).with_limit(
        limit
    ).do()

    result  = response['data']['Get'][weaviate_class_name]
    return result
    
weaviate_client.schema.delete_all()
weaviate_import_data()

@app.route("/ask", methods=["GET"])
def ask():
    question = request.args.get("q")
    prompt = """Rewrite in the style of Shakespeare:
    {content}
    """

    context = weaviate_semantic_search(
        question, 
        prompt
    )

    return {
        "response": context
    }
```
- 構建 Docker 容器並啟動應用程式：
```
cd src/vector_db_generative_search
docker-compose up --build
```
- 在瀏覽器中存取 API。以下是一些範例：http://localhost:5000/ask?q=<your-question>
```
# search query: politics
curl http://0.0.0.0:5000/ask?q=politics
# search query: science
curl http://0.0.0.0:5000/ask?q=science
# search query: cats
curl http://0.0.0.0:5000/ask?q=cats
```
在上述每個命令中，API 將返回基於搜索查詢以莎士比亞風格重寫的文章。

我們在函數中只返回一篇文章。您可以更改限制以返回更多文章並根據上下文生成更多內容。在這種情況下，您將收到來自 OpenAI 的多個回應。limit=1weaviate_semantic_search

在某些情況下，我們需要從具有多個輸入的 OpenAI 獲得單個回應（在我們的例子中是文章）。例如，您可能希望從幾篇文章中提取最重要的資訊，並根據提取的資訊生成一篇新文章。在此方案中，您可以在函數中使用該參數：grouped_taskwith_generate
```
    response = weaviate_client.query.get(
        class_name=weaviate_class_name,
        properties=properties,
    ).with_generate(
        grouped_task=prompt
    ).with_near_text(
        nearText
    ).with_limit(
        limit
    ).do()
```
讓我們考慮一個例子，我們要求OpenAI提取Weaviation返回的一系列文章中討論的主題清單。我們將使用以下提示：
```
prompt = """Extract the list of topics discussed in these articles:
{content}
"""
```
以下是修訂後的代碼：

- src/vector_db_generative_search/app/app.py
```
import weaviate, os, ast
from flask import Flask, request
from openai import OpenAI
import pandas as pd

app = Flask(__name__)

openai_api_key = os.getenv("OPENAI_API_KEY")
model = "gpt-3.5-turbo"
weaviate_class_name = "Article"

openai_client = OpenAI(
    api_key=openai_api_key
)

weaviate_client = weaviate.Client(
    url="http://weaviate:8080",
    auth_client_secret={
        "X-OpenAI-Api-Key": openai_api_key
    }
)

article_class = {
    "class": weaviate_class_name,
    "description": 
        "An article from the Simple English Wikipedia data set",
    "vectorizer": "text2vec-openai",
    "moduleConfig": {
        # Match how OpenAI created the embeddings 
        # for the `content` (`text`) field
        "text2vec-openai": {
            "model": "ada",
            "modelVersion": "002",
            "type": "text",
            "vectorizeClassName": False
        }
    },
    "properties": [
        {
            "name": "title",
            "description": "The title of the article",
            "dataType": ["text"],
            # Don't vectorize the title
            "moduleConfig": {"text2vec-openai": {"skip": True}}
        },
        {
            "name": "content",
            "description": "The content of the article",
            "dataType": ["text"],
        }
    ]
}

def weaviate_import_data():
    counter = 0
    interval = 100
    
    csv_iterator = pd.read_csv(
        'data/data.csv',
        usecols=[
            'id', 
            'url', 
            'title', 
            'text', 
            'content_vector'
        ],
        # number of rows per chunk
        chunksize=100,  
        # limit the number of rows to import
        nrows=100
    )   
    
    # Configure batch
    weaviate_client.batch.configure(
        batch_size=100
    )

    with weaviate_client.batch as batch:
        for chunk in csv_iterator:
            for _, row in chunk.iterrows():

                properties = {
                    "title": row.title,
                    "content": row.text,
                    "url": row.url
                }

                # Convert the vector from CSV 
                # string back to array of floats
                vector = ast.literal_eval(
                    row.content_vector
                )

                # Add the object to the batch, 
                # and set its vector embedding
                batch.add_data_object(
                    properties, 
                    class_name=weaviate_class_name,
                    vector=vector
                )

                # Calculate and display progress
                counter += 1
                if counter % interval == 0:
                    app.logger.debug(f"Imported {counter} articles...")
    app.logger.debug(f"Finished importing {counter} articles.")

def weaviate_semantic_search(query, prompt):
    nearText = {
        "concepts": [query],
    }

    properties = [
        "title", 
        "content",
        "_additional {distance}"
    ]

    limit = 3

    response = weaviate_client.query.get(
        class_name=weaviate_class_name,
        properties=properties,
    ).with_generate(
        grouped_task=prompt
    ).with_near_text(
        nearText
    ).with_limit(
        limit
    ).do()

    result  = response['data']['Get'][weaviate_class_name]
    return result
    
weaviate_client.schema.delete_all()
weaviate_import_data()

@app.route("/ask", methods=["GET"])
def ask():
    question = request.args.get("q")
    prompt = """Extract the list of topics discussed in these articles:
    {content}
    """

    context = weaviate_semantic_search(
        question, 
        prompt
    )

    return {
        "response": context
    }
```
搜索「動物」一詞時，API 將返回有關動物的文章中討論的主題清單。
```
```
{
  "response": [
    {
      "_additional": {
        "distance": 0.17569739,
        "generate": {
          "error": null,
          "groupedResult": "The list of topics discussed in these articles are:\n\n1\
. Animals (zoology, palaeontology, cellular respiration, metabolism, cell membranes)\
\n2. Plants (multicellular eukaryotic organisms)\n3. Grouping animals..."
        }
      },
      "content": "Animals (or Metazoa) are living creatures with many cells...",
      "title": "Animal"
    },
    {
      "_additional": {
        "distance": 0.21414834,
        "generate": null
      },
      "content": "A browser is a name given to any animal, usually a herbivorous mam\
mal ..",
      "title": "Browser"
    },
    {
      "_additional": {
        "distance": 0.22182149,
        "generate": null
      },
      "content": "Being is also a present tense part of to be..",
      "title": "Being"
    }
  ]
}
```
```
生成式搜索對於構建上下文感知應用程式非常有益。下面是一個練習：使用生成式搜索重建前面討論的聊天機器人範例。從一個空的 Weaviate 集合（類）開始，並將聊天消息存儲在 Weaviate 中。

使用生成式搜索根據上下文生成新的聊天消息。
使用小組任務，從這樣的提示開始，測試它，觀察結果，再次測試，依此類推，直到你達到所需的結果：
```
```
prompt = """You are a helpful assistant. You are having a discussion with a user. Th\
is is the context of the discussion:
{content}
"""
```
